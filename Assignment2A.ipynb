{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8029390,"sourceType":"datasetVersion","datasetId":4732530}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Subset, DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport wandb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wandb.login(key=\"\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"h_params =  {\n    \"epochs\":10,\n    \"learning_rate\":0.0001,\n    \"batch_size\":32,\n    \"num_of_filter\":64,\n    \"filter_size\":[3,3,3,3,3],\n    \"actv_func\":\"gelu\",\n    \"filter_multiplier\":2,\n    \"data_augumentation\":False,\n    \"batch_normalization\":True,\n    \"dropout\":0.4,\n    \"conv_layers\":5,\n    \"dense_layer_size\":256\n}\nIMAGE_SIZE = 224\nNUM_OF_CLASSES = 10\nh_params[\"image_size\"] = IMAGE_SIZE\nh_params[\"num_classes\"] = NUM_OF_CLASSES","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DataPreparer:\n    def __init__(self, h_params, image_size, train_dir, val_dir):\n        self.h_params = h_params\n        self.image_size = image_size\n        self.train_dir = train_dir\n        self.val_dir = val_dir\n    def get_train_transform(self):\n        size = (self.image_size, self.image_size)\n        if self.h_params[\"data_augumentation\"]:\n            return transforms.Compose([\n                transforms.Resize(size),\n                transforms.RandomHorizontalFlip(),\n                transforms.RandomVerticalFlip(),\n                transforms.RandomRotation(10),\n                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n                transforms.GaussianBlur(kernel_size=3),\n                transforms.ToTensor()\n            ])\n        else:\n            return transforms.Compose([\n                transforms.Resize(size),\n                transforms.ToTensor()\n            ])\n    def get_test_transform(self):\n        size = (self.image_size, self.image_size)\n        return transforms.Compose([\n            transforms.Resize(size),\n            transforms.ToTensor()\n        ])\n    def stratified_split(self, dataset, ratio):\n        train_idx, val_idx = [], []\n        class_bounds = [\n            (0, 999), (1000, 1999), (2000, 2999), (3000, 3999), (4000, 4998),\n            (4999, 5998), (5999, 6998), (6999, 7998), (7999, 8998), (8999, 9998)\n        ]\n        for start, end in class_bounds:\n            indices = list(range(start, end + 1))\n            split_at = int(len(indices) * ratio)\n            train_idx.extend(indices[:split_at])\n            val_idx.extend(indices[split_at:])\n        return Subset(dataset, train_idx), Subset(dataset, val_idx)\n    def get_datasets(self):\n        train_transform = self.get_train_transform()\n        test_transform = self.get_test_transform()\n        full_train = ImageFolder(self.train_dir, transform=train_transform)\n        train_set, val_set = self.stratified_split(full_train, 0.8)\n        test_set = ImageFolder(self.val_dir, transform=test_transform)\n        return train_set, val_set, test_set\n    def get_loaders(self):\n        train_set, val_set, test_set = self.get_datasets()\n        batch = self.h_params[\"batch_size\"]\n        return {\n            \"train_loader\": DataLoader(train_set, batch_size=batch, shuffle=True),\n            \"val_loader\": DataLoader(val_set, batch_size=batch, shuffle=True),\n            \"test_loader\": DataLoader(test_set, batch_size=batch, shuffle=True),\n            \"train_len\": len(train_set),\n            \"val_len\": len(val_set),\n            \"test_len\": len(test_set)\n        }\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nclass FlexibleCNN(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n        self.features = self._make_feature_extractor()\n        with torch.no_grad():\n            dummy = torch.zeros(1, 3, config['image_size'], config['image_size'])\n            feat_dim = self.features(dummy).view(1, -1).size(1)\n        self.classifier = self._make_classifier(feat_dim)\n    def forward(self, x):\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n    def _make_feature_extractor(self):\n        layers = []\n        in_channels = 3\n        num_filters = self.config['num_of_filter']\n        multiplier = self.config['filter_multiplier']\n        actv = self._get_activation_name(self.config['actv_func'])\n        for i in range(self.config['conv_layers']):\n            out_channels = int(num_filters * (multiplier ** i))\n            kernel_size = self.config['filter_size'][i]\n            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size))\n            if self.config.get('batch_normalization', False):\n                layers.append(nn.BatchNorm2d(out_channels))\n            layers.append(getattr(nn, actv)())\n            layers.append(nn.MaxPool2d(2))\n            in_channels = out_channels\n        return nn.Sequential(*layers)\n    def _make_classifier(self, input_dim):\n        return nn.Sequential(\n            nn.Linear(input_dim, self.config['dense_layer_size']),\n            nn.ReLU(),\n            nn.Dropout(self.config['dropout']),\n            nn.Linear(self.config['dense_layer_size'], self.config['num_classes'])\n        )\n    def _get_activation_name(self, actv_func):\n        mapping = {\n            'elu': 'ELU',\n            'gelu': 'GELU',\n            'silu': 'SiLU',\n            'selu': 'SELU',\n            'leaky_relu': 'LeakyReLU',\n            'relu': 'ReLU'\n        }\n        return mapping.get(actv_func, 'ReLU')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def print_cnn_stats(input_channels, input_size, num_conv_layers, num_filters, filter_size, dense_neurons, num_classes):\n    total_params = 0\n    total_computations = 0\n    in_channels = input_channels\n    size = input_size\n    for i in range(num_conv_layers):\n        conv_params = (filter_size * filter_size * in_channels + 1) * num_filters\n        total_params += conv_params\n        out_size = size - filter_size + 1\n        conv_computations = (filter_size * filter_size * in_channels) * (out_size * out_size) * num_filters\n        total_computations += conv_computations\n        in_channels = num_filters\n        size = out_size // 2\n    flat_features = in_channels * size * size\n    dense_params = flat_features * dense_neurons + dense_neurons\n    total_params += dense_params\n    dense_computations = flat_features * dense_neurons\n    total_computations += dense_computations\n    output_params = dense_neurons * num_classes + num_classes\n    total_params += output_params\n    output_computations = dense_neurons * num_classes\n    total_computations += output_computations\n    print(f\"Total parameters: {total_params}\")\n    print(f\"Total computations (MACs): {total_computations}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef generateGridImage(model, device, loader_data):\n    class_label_names = [\n        \"Amphibia\", \"Animalia\", \"Arachnida\", \"Aves\", \"Fungi\",\n        \"Insecta\", \"Mammalia\", \"Mollusca\", \"Plantae\", \"Reptilia\"\n    ]\n    n_rows, n_cols = 10, 3\n    true_labels, predicted_labels, images = [], [], []\n    test_loader = loader_data['test_loader']\n    data_iterator = iter(test_loader)\n    for _ in range(n_rows * n_cols):\n        inputs, labels = next(data_iterator)\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        true_labels.extend(labels.cpu().numpy())\n        predicted_labels.extend(predicted.cpu().numpy())\n        images.extend(inputs.cpu().numpy())\n    images = np.array(images)\n    images = (images - images.min()) / (images.max() - images.min() + 1e-8)\n    pad_size = 10\n    fig, axs = plt.subplots(n_rows, n_cols, figsize=(12, 30), facecolor=\"#f8f9fa\")\n    fig.suptitle(\n        \"Model Predictions on Test Images\",\n        fontsize=24, fontweight='bold', color=\"#333333\", y=1.02\n    )\n    for i, ax in enumerate(axs.flatten()):\n        img = np.transpose(images[i], (1, 2, 0))\n        true_idx = true_labels[i]\n        pred_idx = predicted_labels[i]\n        correct = (true_idx == pred_idx)\n        img_uint8 = (img * 255).astype(np.uint8)\n        color = (0, 255, 0) if correct else (255, 0, 0)\n        img_padded = cv2.copyMakeBorder(\n            img_uint8, pad_size, pad_size, pad_size, pad_size,\n            borderType=cv2.BORDER_CONSTANT, value=color\n        )\n        img_padded = img_padded.astype(np.float32) / 255.0\n        ax.imshow(img_padded)\n        ax.axis('off')\n        true_label_name = class_label_names[true_idx]\n        predicted_label_name = class_label_names[pred_idx]\n        ax.set_title(\n            f\"True: {true_label_name}\\nPred: {predicted_label_name}\",\n            fontsize=10, fontweight='bold',\n            color='#2ecc40' if correct else '#ff4136',\n            pad=8\n        )\n    plt.figtext(\n        0.5, 0.01,\n        \"Green border = Correct | Red border = Incorrect\",\n        ha=\"center\", fontsize=14, color=\"#555555\"\n    )\n    plt.tight_layout(rect=[0, 0.03, 1, 0.97], pad=2.0)\n    wandb_image = wandb.Image(fig)\n    wandb.log({\"Predictions Grid\": wandb_image})\n    plt.show()\n    plt.close(fig)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, model_class, h_params, training_data):\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.model = model_class(h_params)\n        self.model = torch.nn.DataParallel(self.model, device_ids=[0, 1]).to(self.device)\n        self.h_params = h_params\n        self.loss_fn = nn.CrossEntropyLoss()\n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=h_params[\"learning_rate\"])\n        self.train_loader = training_data['train_loader']\n        self.val_loader = training_data['val_loader']\n        self.test_loader = training_data['test_loader']\n        self.train_len = training_data['train_len']\n        self.val_len = training_data['val_len']\n        self.test_len = training_data['test_len']\n        self.training_data = training_data\n    def fit(self):\n        for epoch in range(self.h_params[\"epochs\"]):\n            train_loss, train_acc = self._train_one_epoch(epoch)\n            val_loss, val_acc = self._validate(epoch)\n            print(f\"epoch: {epoch} train accuracy: {train_acc:.4f} train loss: {train_loss:.4f} val accuracy: {val_acc:.4f} val loss: {val_loss:.4f}\")\n            wandb.log({\n                \"train_accuracy\": train_acc,\n                \"train_loss\": train_loss,\n                \"val_accuracy\": val_acc,\n                \"val_loss\": val_loss,\n                \"epoch\": epoch\n            })\n        test_loss, test_acc = self._test()\n        wandb.log({\n            \"test_accuracy\": test_acc,\n            \"test_loss\": test_loss\n        })\n        print(f'Test accuracy: {test_acc}, Test loss: {test_loss}')\n        generateGridImage(self.model, self.device, self.training_data)\n        print('Finished Training')\n        torch.save(self.model.state_dict(), './bestmodel.pth')\n    def _train_one_epoch(self, epoch):\n        self.model.train()\n        running_loss = 0.0\n        correct = 0\n        for i, (inputs, labels) in enumerate(self.train_loader):\n            inputs, labels = inputs.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self.model(inputs)\n            loss = self.loss_fn(outputs, labels)\n            loss.backward()\n            self.optimizer.step()\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n            if i % 10 == 0:\n                batch_acc = (predicted == labels).float().mean().item()\n                print(f\"epoch {epoch} batch {i} accuracy {batch_acc:.4f} loss {loss.item():.4f}\")\n        avg_loss = running_loss / len(self.train_loader)\n        accuracy = correct / self.train_len\n        return avg_loss, accuracy\n    def _validate(self, epoch):\n        self.model.eval()\n        running_loss = 0.0\n        correct = 0\n        with torch.no_grad():\n            for inputs, labels in self.val_loader:\n                inputs, labels = inputs.to(self.device), labels.to(self.device)\n                outputs = self.model(inputs)\n                loss = self.loss_fn(outputs, labels)\n                running_loss += loss.item()\n                _, predicted = torch.max(outputs, 1)\n                correct += (predicted == labels).sum().item()\n        avg_loss = running_loss / len(self.val_loader)\n        accuracy = correct / self.val_len\n        return avg_loss, accuracy\n    def _test(self):\n        self.model.eval()\n        running_loss = 0.0\n        correct = 0\n        with torch.no_grad():\n            for inputs, labels in self.test_loader:\n                inputs, labels = inputs.to(self.device), labels.to(self.device)\n                outputs = self.model(inputs)\n                loss = self.loss_fn(outputs, labels)\n                running_loss += loss.item()\n                _, predicted = torch.max(outputs, 1)\n                correct += (predicted == labels).sum().item()\n        avg_loss = running_loss / len(self.test_loader)\n        accuracy = correct / self.test_len\n        return avg_loss, accuracy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data_dir = \"/kaggle/input/assignment2dataset/inaturalist_12K/train\"\ntest_data_dir = \"/kaggle/input/assignment2dataset/inaturalist_12K/val\"\ndata_preparer = DataPreparer(h_params, IMAGE_SIZE, train_data_dir, test_data_dir)\ntraining_data = data_preparer.get_loaders()\nrun = wandb.init(\n    project=\"DL Assignment 2\",\n    name=f\"{h_params['actv_func']}_ep_{h_params['epochs']}_lr_{h_params['learning_rate']}_init_fltr_cnt_{h_params['num_of_filter']}_fltr_sz_{h_params['filter_size']}_fltr_mult_{h_params['filter_multiplier']}_data_aug_{h_params['data_augumentation']}_batch_norm_{h_params['batch_normalization']}_dropout_{h_params['dropout']}_dense_size_{h_params['dense_layer_size']}\",\n    config=h_params\n)\nprint_cnn_stats(\n    input_channels=3,\n    input_size=IMAGE_SIZE,\n    num_conv_layers=h_params[\"conv_layers\"],\n    num_filters=h_params[\"num_of_filter\"],\n    filter_size=h_params[\"filter_size\"][0],\n    dense_neurons=h_params[\"dense_layer_size\"],\n    num_classes=NUM_OF_CLASSES\n)\ntrainer = Trainer(FlexibleCNN, h_params, training_data)\ntrainer.fit()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---- Hyperparameter Sweep Setup ----\nsweep_config = {\n    \"method\": \"bayes\",\n    \"name\": \"DL_assignment2_sweep\",\n    \"metric\": {\n        \"goal\": \"maximize\",\n        \"name\": \"val_accuracy\"\n    },\n    \"parameters\": {\n        \"epochs\": {\"values\": [10]},\n        \"learning_rate\": {\"values\": [1e-4, 1e-3]},\n        \"batch_size\": {\"values\": [32, 64]},\n        \"num_of_filter\": {\"values\": [16, 32, 64]},\n        \"filter_size\": {\"values\": [\n            [3,3,3,3,3], [5,5,5,5,5], [7,7,7,7,7], [11,9,7,5,3], [3,5,7,9,11]\n        ]},\n        \"actv_func\": {\"values\": [\"elu\", \"gelu\", \"leaky_relu\", \"selu\"]},\n        \"filter_multiplier\": {\"values\": [1, 2]},\n        \"data_augumentation\": {\"values\": [False]},\n        \"batch_normalization\": {\"values\": [True, False]},\n        \"dropout\": {\"values\": [0, 0.1, 0.2]},\n        \"dense_layer_size\": {\"values\": [64, 128, 256]},\n        \"conv_layers\": {\"values\": [5]}\n    }\n}\n\nsweep_id = wandb.sweep(sweep=sweep_config, project=\"DL Assignment 2\")\ndef main():\n    wandb.init(project=\"DL Assignment 2\")\n    config = wandb.config\n    config = dict(config)\n    config['image_size'] = IMAGE_SIZE\n    config['num_classes'] = NUM_OF_CLASSES\n    train_data_dir = \"/kaggle/input/assignment2dataset/inaturalist_12K/train\"\n    test_data_dir = \"/kaggle/input/assignment2dataset/inaturalist_12K/val\"\n    data_preparer = DataPreparer(config, IMAGE_SIZE, train_data_dir, test_data_dir)\n    training_data = data_preparer.get_loaders()\n    with wandb.init(\n        project=\"DL Assignment 2\",\n        name=f\"{config['actv_func']}_ep_{config['epochs']}_lr_{config['learning_rate']}_init_fltr_cnt_{config['num_of_filter']}_fltr_sz_{config['filter_size']}_fltr_mult_{config['filter_multiplier']}_data_aug_{config['data_augumentation']}_batch_norm_{config['batch_normalization']}_dropout_{config['dropout']}_dense_size_{config['dense_layer_size']}_batch_size_{config['batch_size']}\",\n        config=config\n    ):\n        trainer = Trainer(FlexibleCNN, config, training_data)\n        trainer.fit()\nwandb.agent(sweep_id, function=main, count=10)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-19T20:44:52.367Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = FlexibleCNN(h_params)\nmodel = torch.nn.DataParallel(model, device_ids=[0, 1]).to(device)\nstate_dict = torch.load('./bestmodel.pth', weights_only=True)\nmodel.load_state_dict(state_dict)\nmodel.eval()\n\n\ntrain_data_dir = \"/kaggle/input/assignment2dataset/inaturalist_12K/train\"\ntest_data_dir = \"/kaggle/input/assignment2dataset/inaturalist_12K/val\"\ndata_preparer = DataPreparer(h_params, IMAGE_SIZE, train_data_dir, test_data_dir)\nloader_data = data_preparer.get_loaders()\n\ngenerateGridImage(model, device, loader_data)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}